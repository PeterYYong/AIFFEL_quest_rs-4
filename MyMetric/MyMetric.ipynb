{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTI19xLzio3R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# Load dataset\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "# Vectorize sequences\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "# Define custom MAE metric\n",
        "class MyMetrics(keras.metrics.Metric):\n",
        "    def __init__(self, name=\"mae\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mae_sum = self.add_weight(name=\"mae_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(\n",
        "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "\n",
        "        mae = tf.reduce_sum(tf.abs(y_true - y_pred))\n",
        "        self.mae_sum.assign_add(mae)\n",
        "        num_samples = tf.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return self.mae_sum / tf.cast(self.total_samples, tf.float32)\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mae_sum.assign(0.)\n",
        "        self.total_samples.assign(0)\n",
        "\n",
        "# Build the model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model with the custom MAE metric\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", MyMetrics()])  # Add custom MAE metric here\n",
        "\n",
        "# Train the model\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)\n",
        "\n",
        "# Accessing MAE values during training:\n",
        "# After the model finishes training, you can access the history object to see the MAE values.\n",
        "print(history_original.history)\n",
        "\n",
        "# If 'mae' is present, it will be printed like this:\n",
        "if 'mae' in history_original.history:\n",
        "    print(\"MAE during training:\")\n",
        "    print(history_original.history['mae'])\n",
        "else:\n",
        "    print(\"MAE not found in the history.\")\n",
        "\n",
        "\n",
        "# After training, evaluate the model to get the MAE:\n",
        "# Evaluate the model on the training data (or use a separate test dataset if available)\n",
        "loss, accuracy, mae_value = model.evaluate(train_data, train_labels, verbose=0)\n",
        "\n",
        "# Print the MAE value after training\n",
        "print(\"MAE after training:\", mae_value)"
      ]
    }
  ]
}